# py-trueconsensus
* 1. Networking stack / RPC implementation / guaranteeing delivery probably through message brokers
* 2. DB components
* 3. Integrating with EVM
* 4. Minerva - geth for hybrid
* 5. API components, 
* 6. Interfaces to be exposed 
* 7. Game scenarios for simulation
* 8. Protobuf for requests 
* 9. Config file specs
* 10. Sample bank ledger schema 
* 11. Major hybrid consensus components - subprotocol, mempool, daily offchain consensus, 
* 12. Dummy pow integration
* 13. Internal servers / Testbed preparation
* 14. Packaging 
* 15. Pbft py addition


## 1. Networking stack / RPC implementation / guaranteeing delivery probably through message brokers

The Networking stack, should ensure that when I run this py-trueconsensus on N separate nodes, it should be able to communicate. Versa when I run this locally to simulate, it should run find there too

And that when messages are delivered, packet drops are taken care of. Timeouts are configured. Ping tests are performed. Multicasts, boot tests are ensured.

Pydevp20 https://github.com/ethereum/pydevp2p
Devp2p*
It's already present. We need to integrate that. 
RLPx network layer implementation https://github.com/ethereum/devp2p/blob/master/rlpx.md

Somebody could spend time on this and regardless of status of hybrid, try to simulate with sample codes 
And we could then re use those interfaces in our code

And at the same time, we need to check the latest and the greatest out there in this area. There are researches going on over gossip protocol

So if a dedicated person could look into this, help us in meetings and explain what they learnt and integrate that, we can work together with that person

https://github.com/truechain/py-trueconsensus/tree/master/trueconsensus Does it have that part of the code?
Nope. This is a skeleton but there's a push I'll make by EOD today that should make it more obvious

It will define how imports will be made and where the specific components could be added

## 2. DB components. 
I've decided to go with the conventional Level DB. And will include some more interaction code asap. But I was wondering, whether there exists a database that offers different performance tunables for different records/tables in the db. So we could, during our simulations, observe the heap toast, insert/update etc such activities and find out which DB is making IO intensive calls and all. 

This thought occurred and is necessary because we have a single node unifying 2 protocols - pow and bft. So if we use same DB instance (ideally it doesn't make sense to launch 2 mini clusters on a single computer.), then the update/delete/insert ops in both DB tables will carry different rates of execution
And there's a zlib compression library which is cool too. We need to think about IPFS + concrete data from smart contracts. We might eventually go for a model where, for example in a patent DB or medical record DB , we don't store it all as it is, but maybe through external links or IPFS

So this part (#2) needs to discuss all storage needs

facebook`s rocksdb is not bad, many new blockchain projects are using it
So then accordingly, we'll need to select DB. Maybe we should have a separate session for this discussion
Yeah ricksdb was forked from Google's levelDB for higher performance or something I guess. I'll take another look

Time to market - our roadmap
Feature creep - unwanted investment in feature addition, which might not be popular
Efficiency - zlib supports DEFLATE (LZ77 variation)

Not sure if we should do it right away. But what I meant was whether we should consider data compression and at what stage

I just took the opportunity to discuss major components. We should decide right away, what's feasible within next 2 weeks

## 3. Integrating with EVM
Ethereum community defined EVM in golang and Python for community support
There's always a trade-off